ğŸ§‘â€ğŸ¦¯ Accessible Assistant

An AI-powered Accessible Assistant designed to support blind, deaf, mute, and normal users. The project integrates computer vision, speech technologies, and assistive interfaces to make digital interactions more inclusive.

ğŸš€ Features:

For Blind Users ğŸ‘ï¸:

Object Detection using YOLOv8 + OpenCV

Real-time Book Reader (OCR + Text-to-Speech)

Voice Commands & Navigation

For Deaf Users ğŸ‘‚:

Speech-to-Text (STT) for live transcription

Real-time conversation support

For Mute Users ğŸ—£ï¸:

Text-to-Speech (TTS) for communication

Simple typing â†’ automatic voice output

For Normal Users ğŸ‘¨â€ğŸ’»:

General-purpose assistant features

Volunteer support system

Extra Functionalities:

Gesture-controlled appliances (MediaPipe + OpenCV)

Face Recognition (FaceNet)

Accident Alerting with GNSS + GSM

Volunteer System: Users can request nearby volunteers for help

ğŸ—ï¸ Tech Stack:

Frontend: HTML, Tailwind CSS, JavaScript

Backend: Python (Flask)

AI/ML: OpenCV, YOLOv8, MediaPipe, FaceNet, Tesseract OCR

Speech Tools: pyttsx3, SpeechRecognition, Web Speech API
